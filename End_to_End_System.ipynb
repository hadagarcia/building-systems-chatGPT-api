{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNYNYodhQ0qacDzCx9eRhi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadagarcia/building-systems-chatGPT-api/blob/main/End_to_End_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup:**"
      ],
      "metadata": {
        "id": "D1NpERCY6YwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug-odkWf6K7L"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "\n",
        "import openai\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "#Find a better way to store the key and retrieve it.\n",
        "load_dotenv('/content/sample_data/mis_llaves.env')\n",
        "openai.api_key = os.getenv('OPEN_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra setup required for this Notebook\n",
        "\n",
        "!pip install utils\n",
        "\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "import utils\n",
        "\n",
        "import panel as pn  # GUI\n",
        "pn.extension()"
      ],
      "metadata": {
        "id": "cU223cLM6v1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper method\n",
        "\n",
        "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "0sRvcfBZ8Geh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System of chained prompts for processing the user query"
      ],
      "metadata": {
        "id": "LWGAD9XV8Va1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_user_message(user_input, all_messages, debug=True):\n",
        "    delimiter = \"```\"\n",
        "\n",
        "    # Step 1: Check input to see if it flags the Moderation API or is a prompt injection\n",
        "    response = openai.Moderation.create(input=user_input)\n",
        "    moderation_output = response[\"results\"][0]\n",
        "\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        print(\"Step 1: Input flagged by Moderation API.\")\n",
        "        return \"Sorry, we cannot process this request.\"\n",
        "\n",
        "    if debug: print(\"Step 1: Input passed moderation check.\")\n",
        "\n",
        "    category_and_product_response = utils.find_category_and_product_only(user_input, utils.get_products_and_category())\n",
        "    #print(print(category_and_product_response)\n",
        "\n",
        "    # Step 2: Extract the list of products\n",
        "    category_and_product_list = utils.read_string_to_list(category_and_product_response)\n",
        "    #print(category_and_product_list)\n",
        "\n",
        "    if debug: print(\"Step 2: Extracted list of products.\")\n",
        "\n",
        "    # Step 3: If products are found, look them up\n",
        "    product_information = utils.generate_output_string(category_and_product_list)\n",
        "    if debug: print(\"Step 3: Looked up product information.\")\n",
        "\n",
        "    # Step 4: Answer the user question\n",
        "    system_message = f\"\"\"\n",
        "    You are a customer service assistant for a large electronic store. \\\n",
        "    Respond in a friendly and helpful tone, with concise answers. \\\n",
        "    Make sure to ask the user relevant follow-up questions.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},\n",
        "        {'role': 'assistant', 'content': f\"Relevant product information:\\n{product_information}\"}\n",
        "    ]\n",
        "\n",
        "    final_response = get_completion_from_messages(all_messages + messages)\n",
        "    if debug:print(\"Step 4: Generated response to user question.\")\n",
        "    all_messages = all_messages + messages[1:]\n",
        "\n",
        "    # Step 5: Put the answer through the Moderation API\n",
        "    response = openai.Moderation.create(input=final_response)\n",
        "    moderation_output = response[\"results\"][0]\n",
        "\n",
        "    if moderation_output[\"flagged\"]:\n",
        "        if debug: print(\"Step 5: Response flagged by Moderation API.\")\n",
        "        return \"Sorry, we cannot provide this information.\"\n",
        "\n",
        "    if debug: print(\"Step 5: Response passed moderation check.\")\n",
        "\n",
        "    # Step 6: Ask the model if the response answers the initial user query well\n",
        "    user_message = f\"\"\"\n",
        "    Customer message: {delimiter}{user_input}{delimiter}\n",
        "    Agent response: {delimiter}{final_response}{delimiter}\n",
        "\n",
        "    Does the response sufficiently answer the question?\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_message},\n",
        "        {'role': 'user', 'content': user_message}\n",
        "    ]\n",
        "    evaluation_response = get_completion_from_messages(messages)\n",
        "    if debug: print(\"Step 6: Model evaluated the response.\")\n",
        "\n",
        "    # Step 7: If yes, use this answer; if not, say that you will connect the user to a human\n",
        "    if \"Y\" in evaluation_response:  # Using \"in\" instead of \"==\" to be safer for model output variation (e.g., \"Y.\" or \"Yes\")\n",
        "        if debug: print(\"Step 7: Model approved the response.\")\n",
        "        return final_response, all_messages\n",
        "    else:\n",
        "        if debug: print(\"Step 7: Model disapproved the response.\")\n",
        "        neg_str = \"I'm unable to provide the information you're looking for. I'll connect you with a human representative for further assistance.\"\n",
        "        return neg_str, all_messages\n"
      ],
      "metadata": {
        "id": "QPfIbM-k8YQD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"tell me about the smartx pro phone and the fotosnap camera, the dslr one. Also what tell me about your tvs\"\n",
        "response,_ = process_user_message(user_input,[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "7RT9lG5--dWO",
        "outputId": "bc59d247-4a20-479c-c94e-d67a4f84a684"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Input passed moderation check.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7cdf8c7a4396>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tell me about the smartx pro phone and the fotosnap camera, the dslr one. Also what tell me about your tvs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_user_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f1bd0a3620c4>\u001b[0m in \u001b[0;36mprocess_user_message\u001b[0;34m(user_input, all_messages, debug)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step 1: Input passed moderation check.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcategory_and_product_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_category_and_product_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_products_and_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print(print(category_and_product_response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'find_category_and_product_only'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that collects user and assistant messages over time"
      ],
      "metadata": {
        "id": "QqZ208x1AV40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_messages(debug=False):\n",
        "    user_input = inp.value_input\n",
        "    if debug: print(f\"User Input = {user_input}\")\n",
        "    if user_input == \"\":\n",
        "        return\n",
        "    inp.value = ''\n",
        "    global context\n",
        "    #response, context = process_user_message(user_input, context, utils.get_products_and_category(),debug=True)\n",
        "    response, context = process_user_message(user_input, context, debug=False)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(user_input, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
        "\n",
        "    return pn.Column(*panels)"
      ],
      "metadata": {
        "id": "iGR1qIqKAYZT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chat with the chatbot!**\n",
        "\n",
        "\n",
        "Note that the system message includes detailed instructions about what the OrderBot should do."
      ],
      "metadata": {
        "id": "9DYq2NjxAgZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panels = [] # collect display\n",
        "\n",
        "context = [ {'role':'system', 'content':\"You are Service Assistant\"} ]\n",
        "\n",
        "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
        "button_conversation = pn.widgets.Button(name=\"Service Assistant\")\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
        ")\n",
        "\n",
        "dashboard"
      ],
      "metadata": {
        "id": "zMGdFwTCAjov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}